{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER with NLTK HMM with Words as features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " |#ID | #Gold Standard | #Found | #Correct | Precision | Recall | F-1 |\n",
    " |----|----------------|--------|----------|-----------|--------|-----|\n",
    "|1|3413|1441|832|0.577376821652|0.243773806036|0.342810053564|\n",
    "|2|3413|2540|1370|0.53937007874|0.401406387343|0.460272131698|\n",
    "|3|3413|2434|1308|0.537387017256|0.383240550835|0.447408927655|\n",
    "|4|3167|2418|1318|0.545078577337|0.416166719293|0.471978513876|\n",
    " 1. Training on 80% of data and 20 % dev with NLTK HMM with words as features\n",
    " 2. Training on 80% of data and 20 % dev with NLTK HMM with words as features\n",
    "     - Removing Low Frequency Words <= 1\n",
    " 3. Training on 80% of data and 20 % dev with NLTK HMM with words as features\n",
    "     - Removing Low Frequency Words <= 2\n",
    " 2. Random sample training on 80% of data and 20 % dev with NLTK HMM with words as features\n",
    "     - Removing Low Frequency Words <= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T04:03:52.843406Z",
     "start_time": "2017-12-05T04:03:52.471135Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from StringIO import StringIO\n",
    "from evalNER import eval\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import nltk\n",
    "from nltk.tag import hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T04:03:52.858382Z",
     "start_time": "2017-12-05T04:03:52.844561Z"
    }
   },
   "outputs": [],
   "source": [
    "text = open(\"./gene-trainF17.txt\").read()\n",
    "lines = [ y.strip() for y in text.split(\"\\n\\n\")]\n",
    "raw_df = pd.DataFrame(lines, columns = [\"sentence\"])\n",
    "# np.random.seed(1234)\n",
    "msk = np.random.rand(len(raw_df)) < 0.8\n",
    "train_df = raw_df[msk]\n",
    "dev_df = raw_df[~msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T04:03:52.861760Z",
     "start_time": "2017-12-05T04:03:52.859516Z"
    }
   },
   "outputs": [],
   "source": [
    "df = raw_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T04:03:53.274308Z",
     "start_time": "2017-12-05T04:03:52.862902Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[:, \"sentence_token\"] = df[\"sentence\"].apply(lambda x : tuple(y.split(\"\\t\") for y in x.split(\"\\n\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T04:03:53.358764Z",
     "start_time": "2017-12-05T04:03:53.275435Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[:, \"tags\"] = df[\"sentence_token\"].apply(lambda x : tuple(y[2] for y in x))\n",
    "df.loc[:, \"words\"] = df[\"sentence_token\"].apply(lambda x : tuple(y[1] for y in x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T04:03:53.385965Z",
     "start_time": "2017-12-05T04:03:53.359856Z"
    }
   },
   "outputs": [],
   "source": [
    "count_df = df[\"words\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T04:03:53.601464Z",
     "start_time": "2017-12-05T04:03:53.387367Z"
    }
   },
   "outputs": [],
   "source": [
    "word_counter = Counter()\n",
    "for k, v in count_df.iteritems():\n",
    "    temp_counter = Counter()\n",
    "    for w in k:\n",
    "        word_counter[w] += v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T04:03:53.614184Z",
     "start_time": "2017-12-05T04:03:53.602694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14131\n"
     ]
    }
   ],
   "source": [
    "V = set(k for k, v in word_counter.iteritems() if v > 1)\n",
    "print len(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T04:03:53.707767Z",
     "start_time": "2017-12-05T04:03:53.615417Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"words\"] = df[\"words\"].apply(lambda x: tuple(y if y in V else \"UNK\" for y in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T04:03:54.083316Z",
     "start_time": "2017-12-05T04:03:53.708962Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"words_tags\"] = df[[\"words\", \"tags\"]].apply(lambda x : zip(x[0],x[1]), axis = 1)\n",
    "features = df[\"words_tags\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T04:03:54.777685Z",
     "start_time": "2017-12-05T04:03:54.084547Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = hmm.HiddenMarkovModelTrainer()\n",
    "tagger = trainer.train_supervised(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T04:03:54.814788Z",
     "start_time": "2017-12-05T04:03:54.779211Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = open(\"./F17-assgn4-test.txt\").read()\n",
    "lines = [ y.strip() for y in text.split(\"\\n\\n\")]\n",
    "dev_df = pd.DataFrame(lines, columns = [\"sentence\"])\n",
    "test_df = dev_df.copy()\n",
    "test_df.loc[:, \"sentence_token\"] = test_df[\"sentence\"].apply(lambda x : [y.split(\"\\t\") for y in x.split(\"\\n\")])\n",
    "test_df.loc[:, \"words\"] = test_df[\"sentence_token\"].apply(lambda x : tuple(y[1] for y in x))\n",
    "test_df.loc[:, \"words_\"] = test_df[\"words\"].apply(lambda x : tuple(y if y in V else \"UNK\" for y in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T04:03:55.314395Z",
     "start_time": "2017-12-05T04:03:54.816510Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df.loc[:, \"prediction\"] = test_df[[\"words_\", \"words\"]].apply(lambda x: tuple(\"\\t\".join([x[0], x[1][1]]) for x in zip(x[\"words\"], tagger.tag(x[\"words_\"]))), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T04:03:55.326613Z",
     "start_time": "2017-12-05T04:03:55.315655Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df.loc[:, \"temp1\"] = test_df[\"prediction\"].apply(lambda x : tuple(str(i) + \"\\t\" + y for i,y in enumerate(x,1)))\n",
    "test_df.loc[:, \"temp1\"] = test_df[\"temp1\"].apply(lambda x : \"\\n\".join(x))\n",
    "predictions = \"\\n\\n\".join(test_df[\"temp1\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T04:05:09.368984Z",
     "start_time": "2017-12-05T04:05:09.360971Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"test_out_hmm.txt\", \"w\") as f:\n",
    "    f.write(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "notify_time": "5",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
